# -*- coding: utf-8 -*-
"""MLExercise_WineQualityRF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14AT7LOMvod-NwiTPZuv9yCswAFQXJRkc

# Wine Quality prediction using Decision Forest
Classification exercise using TensorFlow

[TensorFlow Decision Forests](https://www.tensorflow.org/decision_forests)

[Exercise example: Ranking Conditions](https://www.tensorflow.org/decision_forests/tutorials/beginner_colab#installing_tensorflow_decision_forests)

[Exercise example: Building a soft decision tree, from scratch](https://towardsdatascience.com/building-a-decision-tree-in-tensorflow-742438cb483e)

[Exercise example: K-means cluster, from scratch](https://towardsdatascience.com/k-means-clustering-from-scratch-6a9d19cafc25)
"""

!pip install tensorflow_decision_forests -q
!pip install shap -q
import tensorflow_decision_forests as tfdf

import os
import numpy as np
import pandas as pd
import tensorflow as tf
import shap
import math

!pip install wurlitzer -q
try:
  from wurlitzer import sys_pipes
except:
  from colabtools.googlelog import CaptureLog as sys_pipes

from IPython.core.magic import register_line_magic
from IPython.display import Javascript

!pip install bokeh -q
import scipy.special

from bokeh.layouts import gridplot
from bokeh.plotting import figure, show
from bokeh.resources import INLINE
import bokeh.io

bokeh.io.output_notebook(INLINE)

def make_plot(title, hist, edges, x, pdf, cdf):
    p = figure(title=title, tools='', background_fill_color="#fafafa")
    p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:],
           fill_color="navy", line_color="white", alpha=0.5)
    p.line(x, pdf, line_color="#ff8888", line_width=4, alpha=0.7, legend_label="PDF")
    p.line(x, cdf, line_color="orange", line_width=2, alpha=0.7, legend_label="CDF")

    p.y_range.start = 0
    p.legend.location = "center_right"
    p.legend.background_fill_color = "#fefefe"
    p.xaxis.axis_label = 'x'
    p.yaxis.axis_label = 'Pr(x)'
    p.grid.grid_line_color="white"
    return p

def plot_distribution_check(vec_review, str_name):

    hist, edges = np.histogram(vec_review, density=True, bins=50)

    x_min = min(vec_review)
    x_max = max(vec_review)
    x_mu  = np.mean(vec_review)
    x_sig = np.std(vec_review)

    x = np.linspace(x_min, x_max, 1000)
    pdf = 1/(x_sig * np.sqrt(2*np.pi)) * np.exp(-(x-x_mu)**2 / (2*x_sig**2))
    cdf = (1+scipy.special.erf((x-x_mu)/np.sqrt(2*x_sig**2)))/2

    plt_obj = make_plot(f"DIstribution checks for: {str_name}", hist, edges, x, pdf, cdf)

    return plt_obj

"""## Import and process data

Wine quality data provided by [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/wine+quality)
"""

# Wine data
str_df_red = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'
str_df_white = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'

df_red = pd.read_csv(str_df_red, sep = ';')
df_wht = pd.read_csv(str_df_white, sep = ';')

df_red.head(3)

# Histogram plots
str_check = df_red.columns.to_list();
vec_plot = []

for iter in str_check:
  vec_plot.append(plot_distribution_check(df_red[iter], iter))
show(gridplot(vec_plot, ncols=3, plot_width =400, plot_height=400, toolbar_location=None))

"""Some data transformations are recommended:
* alcohol - log scale
* free sulfer dioxide - log scale
* total sulfer dioxide - log scale
"""

df_red['alcohol'] = np.log(df_red['alcohol'])
df_red['free sulfur dioxide'] = np.log(df_red['free sulfur dioxide'])
df_red['total sulfur dioxide'] = np.log(df_red['total sulfur dioxide'] )

# Re-check the variables
# Histogram plots
str_check = df_red.columns.to_list();
vec_plot = []

for iter in str_check:
  vec_plot.append(plot_distribution_check(df_red[iter], iter))
show(gridplot(vec_plot, ncols=3, plot_width =400, plot_height=400, toolbar_location=None))

df_wht.head(3)

df_red.loc[:,'quality'] = df_red['quality'].map(str)
classes = sorted(df_red['quality'].unique().tolist())
print(classes)

df_red['quality'] = df_red.quality.map(classes.index)

#df_red['quality_bool'] = ['good' if iter > 5 else 'bad' for iter in df_red.quality]
#df_wht['quality_bool'] = ['good' if iter > 5 else 'bad' for iter in df_wht.quality]

"""Function to split test and train"""

# Split the dataset into a training and a testing dataset.

def split_dataset(dataset, test_ratio=0.30):
  """Splits a panda dataframe in two."""
  test_indices = np.random.rand(len(dataset)) < test_ratio
  return dataset[~test_indices], dataset[test_indices]


train_ds_red, test_ds_red = split_dataset(df_red)
print(f"Red Wine: {len(train_ds_red)} examples in training, {len(test_ds_red)} examples for testing.")
train_ds_white, test_ds_white = split_dataset(df_wht)
print(f"White Wine: {len(train_ds_white)} examples in training, {len(test_ds_white)} examples for testing.")

"""## Red wine prediction"""

# Variable of interest 
label = 'quality'
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_red, label=label)
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_red, label=label)

def vec_prediction(predict_prob):
  
  n, n_prob = predict_prob.shape

  vec_pred_class = [0] * n
  vec_pred_class_idx = [0] * n
  vec_pred_unc  = [0] * n

  for iter in range(0, n):
    vec_prob = predict_prob[iter, :]
    # Most likely based on maximum of probability
    
    idx_likely = list(vec_prob).index(max(vec_prob))
    #   save the index, for comparison reason
    vec_pred_class_idx[iter] = idx_likely

    # save the prediction
    vec_pred_class[iter] = classes[idx_likely]
    
    # Save standard error of prediction probability
    vec_pred_unc[iter] = np.std(vec_prob)

  return vec_pred_class_idx, vec_pred_class, vec_pred_unc

"""### What's up with the __LABEL?"""

#%set_cell_height 300

# Specify the model.
model_1 = tfdf.keras.RandomForestModel()

# Optionally, add evaluation metrics.
model_1.compile(metrics=["accuracy"])

# Train the model.
# "sys_pipes" is optional. It enables the display of the training logs.
with sys_pipes():
  model_1.fit(x=train_ds)

"""### Evaluation"""

evaluation = model_1.evaluate(test_ds, return_dict=True)
print()

for name, value in evaluation.items():
  print(f"{name}: {value:.4f}")

tfdf.model_plotter.plot_model_in_colab(model_1, tree_idx=0, max_depth=4)

"""### Prediction measurements"""

predict_prob = model_1.predict(x = test_ds)

# Get model output for test sample
vec_pred_class_idx, vec_pred_class, vec_pred_unc = vec_prediction(predict_prob)

# Reset index for use:
test_ds_red.reset_index(drop = True, inplace = True)
# save the result in the dataframe
test_ds_red['quality_pred'] = vec_pred_class_idx
test_ds_red['pred_class_correct'] = [1 if (val == test_ds_red.quality[iter]) 
                                        else 0 for (iter, val) in enumerate(test_ds_red.quality_pred)]

print(f'Test set accuracy: {round( np.mean(test_ds_red.pred_class_correct) *100, 2)} percent')

# 67.9 percent for no data transformation (log-scale)

model_1.summary()

# The input features
model_1.make_inspector().features()

# The feature importances
model_1.make_inspector().variable_importances()

"""### Training and validation data"""

# Commented out IPython magic to ensure Python compatibility.
# This cell start TensorBoard that can be slow.
# Load the TensorBoard notebook extension
# %load_ext tensorboard
# Google internal version
# %load_ext google3.learning.brain.tensorboard.notebook.extension

# Clear existing results (if any)
rm -fr "/tmp/tensorboard_logs"

# Export the meta-data to tensorboard.
model_1.make_inspector().export_to_tensorboard("/tmp/tensorboard_logs")

# Start a tensorboard instance.
# %tensorboard --logdir "/tmp/tensorboard_logs"

"""## Iteration 2: combining Red wine & White wine data 

"""

df_red = pd.read_csv(str_df_red, sep = ';')
df_wht = pd.read_csv(str_df_white, sep = ';')

# Create indicator for each
df_red['idx_red'] = 1
df_wht['idx_red'] = 0
df = pd.concat([df_red, df_wht])

df['alcohol'] = np.log(df['alcohol'])
df['free sulfur dioxide'] = np.log(df['free sulfur dioxide'])
df['total sulfur dioxide'] = np.log(df['total sulfur dioxide'] )

# White wine
df.loc[:,'quality'] = df['quality'].map(str)
classes = sorted(df['quality'].unique().tolist())
print(classes)

df['quality'] = df.quality.map(classes.index)

"""### Model fit"""

def split_dataset(dataset, test_ratio=0.30):
  """Splits a panda dataframe in two."""
  test_indices = np.random.rand(len(dataset)) < test_ratio
  return dataset[~test_indices], dataset[test_indices]


train_ds_df, test_ds_df = split_dataset(df)

# Variable of interest 
label = 'quality'
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_df, label=label)
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_df, label=label)

# Specify the model.
model_2 = tfdf.keras.RandomForestModel()

# Optionally, add evaluation metrics.
model_2.compile(metrics=["accuracy"])

# Train the model.
# "sys_pipes" is optional. It enables the display of the training logs.
with sys_pipes():
  model_2.fit(x=train_ds)

# Evaluate the model
evaluation = model_2.evaluate(test_ds, return_dict=True)

train_ds_eval = train_ds_df.copy()

predict_prob = model_2.predict(x = train_ds)

# Get model output for test sample
vec_pred_class_idx, vec_pred_class, vec_pred_unc = vec_prediction(predict_prob)

# Reset index for use:
train_ds_eval.reset_index(drop = True, inplace = True)
# save the result in the dataframe
train_ds_eval['quality_pred'] = vec_pred_class_idx
train_ds_eval['pred_class_correct'] = [1 if (val == train_ds_eval.quality[iter]) 
                                        else 0 for (iter, val) in enumerate(train_ds_eval.quality_pred)]

print(f'Train set accuracy: {round( np.mean(train_ds_eval.pred_class_correct) *100, 2)} percent')

test_ds_eval = test_ds_df.copy()

predict_prob = model_2.predict(x = test_ds)

# Get model output for test sample
vec_pred_class_idx, vec_pred_class, vec_pred_unc = vec_prediction(predict_prob)

# Reset index for use:
test_ds_eval.reset_index(drop = True, inplace = True)
# save the result in the dataframe
test_ds_eval['quality_pred'] = vec_pred_class_idx
test_ds_eval['pred_class_correct'] = [1 if (val == test_ds_eval.quality[iter]) 
                                        else 0 for (iter, val) in enumerate(test_ds_eval.quality_pred)]

print(f'Test set accuracy: {round( np.mean(test_ds_eval.pred_class_correct) *100, 2)} percent')

# 67.9 percent for no data transformation (log-scale)